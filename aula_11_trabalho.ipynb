{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste 7 - Fazer a atividades combinada na aula de 30/10/24\n",
    "\n",
    "Aluno: Thiago Cesar Emrich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8498 - loss: 0.4906 - val_accuracy: 0.9600 - val_loss: 0.1309\n",
      "Epoch 2/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9686 - loss: 0.1054 - val_accuracy: 0.9629 - val_loss: 0.1211\n",
      "Epoch 3/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9783 - loss: 0.0702 - val_accuracy: 0.9686 - val_loss: 0.1098\n",
      "Epoch 4/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9834 - loss: 0.0562 - val_accuracy: 0.9704 - val_loss: 0.1059\n",
      "Epoch 5/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9859 - loss: 0.0439 - val_accuracy: 0.9683 - val_loss: 0.1207\n",
      "Epoch 6/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9889 - loss: 0.0379 - val_accuracy: 0.9623 - val_loss: 0.1390\n",
      "Epoch 7/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9876 - loss: 0.0421 - val_accuracy: 0.9721 - val_loss: 0.1483\n",
      "Epoch 8/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9917 - loss: 0.0283 - val_accuracy: 0.9732 - val_loss: 0.1222\n",
      "Epoch 9/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9910 - loss: 0.0303 - val_accuracy: 0.9785 - val_loss: 0.1071\n",
      "Epoch 10/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9936 - loss: 0.0228 - val_accuracy: 0.9739 - val_loss: 0.1198\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "# Load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Verify dataset shape\n",
    "assert x_train.shape == (60000, 28, 28)\n",
    "assert x_test.shape == (10000, 28, 28)\n",
    "assert y_train.shape == (60000,)\n",
    "assert y_test.shape == (10000,)\n",
    "\n",
    "# Pick a sample to plot\n",
    "sample = 1\n",
    "image = x_train[sample]\n",
    "\n",
    "# Plot the sample\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(f\"Label: {y_train[sample]}\")  # Add title with label\n",
    "plt.show()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255  # Normalize the data\n",
    "x_train = x_train.reshape(-1, 784).astype('float32')  # Flatten the images\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding)\n",
    "train_labels = keras.utils.to_categorical(y_train).astype('float32')\n",
    "\n",
    "# Split data into training and validation sets\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, train_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define model architecture\n",
    "input_num_units = 784\n",
    "hidden1_num_units = 500\n",
    "hidden2_num_units = 500\n",
    "hidden3_num_units = 500\n",
    "hidden4_num_units = 500\n",
    "hidden5_num_units = 500\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(input_num_units,)),  # Use Input layer to specify input shape\n",
    "    Dense(hidden1_num_units, activation='relu'),\n",
    "    Dense(hidden2_num_units, activation='relu'),\n",
    "    Dense(hidden3_num_units, activation='relu'),\n",
    "    Dense(hidden4_num_units, activation='relu'),\n",
    "    Dense(hidden5_num_units, activation='relu'),\n",
    "    Dense(output_num_units, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "trained_model_5d = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando o Regularizador L2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8451 - loss: 0.7071 - val_accuracy: 0.9566 - val_loss: 0.3225\n",
      "Epoch 2/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9658 - loss: 0.2788 - val_accuracy: 0.9680 - val_loss: 0.2665\n",
      "Epoch 3/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9767 - loss: 0.2275 - val_accuracy: 0.9657 - val_loss: 0.2596\n",
      "Epoch 4/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9778 - loss: 0.2100 - val_accuracy: 0.9727 - val_loss: 0.2182\n",
      "Epoch 5/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9845 - loss: 0.1702 - val_accuracy: 0.9733 - val_loss: 0.2115\n",
      "Epoch 6/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9856 - loss: 0.1606 - val_accuracy: 0.9736 - val_loss: 0.2035\n",
      "Epoch 7/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9877 - loss: 0.1431 - val_accuracy: 0.9744 - val_loss: 0.1939\n",
      "Epoch 8/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9897 - loss: 0.1287 - val_accuracy: 0.9697 - val_loss: 0.2079\n",
      "Epoch 9/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9884 - loss: 0.1260 - val_accuracy: 0.9768 - val_loss: 0.1735\n",
      "Epoch 10/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9915 - loss: 0.1144 - val_accuracy: 0.9753 - val_loss: 0.1713\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(input_num_units,)),  # Use Input layer to specify input shape\n",
    "    Dense(hidden1_num_units, activation='relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
    "    Dense(hidden2_num_units, activation='relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
    "    Dense(hidden3_num_units, activation='relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
    "    Dense(hidden4_num_units, activation='relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
    "    Dense(hidden5_num_units, activation='relu', kernel_regularizer=regularizers.l2(0.0001)),\n",
    "    Dense(output_num_units, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "trained_model_5d = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando o Regularizador L1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8395 - loss: 3.7200 - val_accuracy: 0.9454 - val_loss: 1.5774\n",
      "Epoch 2/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9586 - loss: 1.3159 - val_accuracy: 0.9463 - val_loss: 0.8810\n",
      "Epoch 3/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9642 - loss: 0.7435 - val_accuracy: 0.9607 - val_loss: 0.5711\n",
      "Epoch 4/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9692 - loss: 0.5071 - val_accuracy: 0.9697 - val_loss: 0.4282\n",
      "Epoch 5/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9734 - loss: 0.3945 - val_accuracy: 0.9681 - val_loss: 0.3636\n",
      "Epoch 6/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9760 - loss: 0.3337 - val_accuracy: 0.9654 - val_loss: 0.3394\n",
      "Epoch 7/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9793 - loss: 0.2836 - val_accuracy: 0.9644 - val_loss: 0.3222\n",
      "Epoch 8/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9807 - loss: 0.2591 - val_accuracy: 0.9706 - val_loss: 0.2878\n",
      "Epoch 9/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9800 - loss: 0.2532 - val_accuracy: 0.9701 - val_loss: 0.2765\n",
      "Epoch 10/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9851 - loss: 0.2217 - val_accuracy: 0.9728 - val_loss: 0.2600\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(input_num_units,)),  # Use Input layer to specify input shape\n",
    "    Dense(hidden1_num_units, activation='relu', kernel_regularizer=regularizers.l1(0.0001)),\n",
    "    Dense(hidden2_num_units, activation='relu', kernel_regularizer=regularizers.l1(0.0001)),\n",
    "    Dense(hidden3_num_units, activation='relu', kernel_regularizer=regularizers.l1(0.0001)),\n",
    "    Dense(hidden4_num_units, activation='relu', kernel_regularizer=regularizers.l1(0.0001)),\n",
    "    Dense(hidden5_num_units, activation='relu', kernel_regularizer=regularizers.l1(0.0001)),\n",
    "    Dense(output_num_units, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "trained_model_5d = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando o Regularizador Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.7628 - loss: 0.7140 - val_accuracy: 0.9539 - val_loss: 0.1572\n",
      "Epoch 2/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9481 - loss: 0.1726 - val_accuracy: 0.9644 - val_loss: 0.1219\n",
      "Epoch 3/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9650 - loss: 0.1224 - val_accuracy: 0.9682 - val_loss: 0.1169\n",
      "Epoch 4/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9675 - loss: 0.1128 - val_accuracy: 0.9720 - val_loss: 0.1064\n",
      "Epoch 5/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9719 - loss: 0.0896 - val_accuracy: 0.9712 - val_loss: 0.1071\n",
      "Epoch 6/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9781 - loss: 0.0776 - val_accuracy: 0.9733 - val_loss: 0.1054\n",
      "Epoch 7/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9810 - loss: 0.0683 - val_accuracy: 0.9745 - val_loss: 0.0978\n",
      "Epoch 8/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9818 - loss: 0.0607 - val_accuracy: 0.9751 - val_loss: 0.0929\n",
      "Epoch 9/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9837 - loss: 0.0578 - val_accuracy: 0.9781 - val_loss: 0.0985\n",
      "Epoch 10/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9850 - loss: 0.0517 - val_accuracy: 0.9782 - val_loss: 0.0954\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(input_num_units,)),  # Input layer specifying the input shape\n",
    "    Dense(hidden1_num_units, activation='relu'),\n",
    "    Dropout(0.25),  # Dropout layer after the Dense layer\n",
    "    Dense(hidden2_num_units, activation='relu'),\n",
    "    Dropout(0.25),  # Dropout layer after the Dense layer\n",
    "    Dense(hidden3_num_units, activation='relu'),\n",
    "    Dropout(0.25),  # Dropout layer after the Dense layer\n",
    "    Dense(hidden4_num_units, activation='relu'),\n",
    "    Dropout(0.25),  # Dropout layer after the Dense layer\n",
    "    Dense(hidden5_num_units, activation='relu'),\n",
    "    Dropout(0.25),  # Dropout layer after the Dense layer\n",
    "    Dense(output_num_units, activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "trained_model_5d = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserindo Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\UT6E\\AppData\\Local\\miniforge3\\envs\\datamining\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1047: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "\n",
    "# Load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Verify dataset shape\n",
    "assert x_train.shape == (60000, 28, 28)\n",
    "assert x_test.shape == (10000, 28, 28)\n",
    "assert y_train.shape == (60000,)\n",
    "assert y_test.shape == (10000,)\n",
    "\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.astype('float32') / 255  # Normalize the data\n",
    "x_train = np.expand_dims(x_train, -1)  # Reshape to (60000, 28, 28, 1) for ImageDataGenerator\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding)\n",
    "train_labels = keras.utils.to_categorical(y_train).astype('float32')\n",
    "\n",
    "# Split data into training and validation sets\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, train_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create an ImageDataGenerator with ZCA whitening\n",
    "datagen = ImageDataGenerator(zca_whitening=True)\n",
    "\n",
    "# Fit the generator on training data for ZCA whitening\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Optionally, you can use datagen.flow(x_train, y_train, batch_size=32) for batch training in a model\n",
    "datagen.flow(x_train, y_train, batch_size=32)\n",
    "\n",
    "\n",
    "## reshaping\n",
    "x_train=np.reshape(x_train,(x_train.shape[0],-1))/255\n",
    "x_valid=np.reshape(x_valid,(x_valid.shape[0],-1))/255\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando Dropout no novo data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.4438 - loss: 1.4780 - val_accuracy: 0.8781 - val_loss: 0.3943\n",
      "Epoch 2/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8803 - loss: 0.3971 - val_accuracy: 0.9058 - val_loss: 0.2965\n",
      "Epoch 3/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9216 - loss: 0.2667 - val_accuracy: 0.9383 - val_loss: 0.2106\n",
      "Epoch 4/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9364 - loss: 0.2132 - val_accuracy: 0.9477 - val_loss: 0.1753\n",
      "Epoch 5/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9447 - loss: 0.1905 - val_accuracy: 0.9579 - val_loss: 0.1435\n",
      "Epoch 6/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9486 - loss: 0.1686 - val_accuracy: 0.9572 - val_loss: 0.1535\n",
      "Epoch 7/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9527 - loss: 0.1620 - val_accuracy: 0.9577 - val_loss: 0.1416\n",
      "Epoch 8/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9609 - loss: 0.1291 - val_accuracy: 0.9581 - val_loss: 0.1431\n",
      "Epoch 9/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9621 - loss: 0.1289 - val_accuracy: 0.9654 - val_loss: 0.1200\n",
      "Epoch 10/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9648 - loss: 0.1220 - val_accuracy: 0.9667 - val_loss: 0.1177\n"
     ]
    }
   ],
   "source": [
    "# Define model architecture\n",
    "input_num_units = 784\n",
    "hidden1_num_units = 500\n",
    "hidden2_num_units = 500\n",
    "hidden3_num_units = 500\n",
    "hidden4_num_units = 500\n",
    "hidden5_num_units = 500\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(input_num_units,)),  # Input layer specifying the input shape\n",
    "    Dense(hidden1_num_units, activation='relu'),\n",
    "    Dropout(0.25),  # Dropout layer after the Dense layer\n",
    "    Dense(hidden2_num_units, activation='relu'),\n",
    "    Dropout(0.25),  # Dropout layer after the Dense layer\n",
    "    Dense(hidden3_num_units, activation='relu'),\n",
    "    Dropout(0.25),  # Dropout layer after the Dense layer\n",
    "    Dense(hidden4_num_units, activation='relu'),\n",
    "    Dropout(0.25),  # Dropout layer after the Dense layer\n",
    "    Dense(hidden5_num_units, activation='relu'),\n",
    "    Dropout(0.25),  # Dropout layer after the Dense layer\n",
    "    Dense(output_num_units, activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "trained_model_5d = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Early Stopping Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9631 - loss: 0.1270 - val_accuracy: 0.9647 - val_loss: 0.1225\n",
      "Epoch 2/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9661 - loss: 0.1139 - val_accuracy: 0.9652 - val_loss: 0.1272\n",
      "Epoch 3/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9633 - loss: 0.1240 - val_accuracy: 0.9699 - val_loss: 0.1059\n",
      "Epoch 4/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9719 - loss: 0.0954 - val_accuracy: 0.9668 - val_loss: 0.1222\n",
      "Epoch 5/10\n",
      "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9722 - loss: 0.0929 - val_accuracy: 0.9683 - val_loss: 0.1088\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=2)\n",
    "\n",
    "# Train the model\n",
    "trained_model_5d = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
